# Cross-Validation 3: Leave-One-Out and Stratified Cross-Validation

Leave-One-Out Cross-Validation (LOOCV) and Stratified Cross-Validation are variations of cross-validation techniques that offer unique advantages in specific scenarios.

- LOOCV involves leaving out one data point as a test set and using the rest for training, repeating this process for all data points. It's valuable for small datasets.
- Stratified Cross-Validation maintains the class distribution in each fold, making it suitable for imbalanced datasets.

In this section, we'll explore LOOCV and Stratified CV, explain when to use them, and provide code examples for their implementation in Python.

Understanding these specialized cross-validation techniques will enhance your ability to evaluate and fine-tune your linear regression models effectively.

[Continue to Cross-Validation 4: Practical Tips and Best Practices ➡️](cross_validation_best_practices.md)

