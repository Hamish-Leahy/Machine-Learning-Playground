# Cross-Validation 1: Introduction to Cross-Validation

Cross-validation is a fundamental technique used to assess the performance and generalization ability of machine learning models, including linear regression. It helps mitigate issues like overfitting and provides a more robust evaluation of model performance.

In this section, we'll introduce the concept of cross-validation, explain why it's important, and discuss its various methods, including k-fold cross-validation, leave-one-out cross-validation, and stratified cross-validation.

We'll also cover the benefits and potential pitfalls of cross-validation, setting the stage for practical implementation.

By understanding cross-validation, you'll be better equipped to evaluate your linear regression models effectively.

[Continue to Cross-Validation 2: K-Fold Cross-Validation ➡️](cross_validation_k_fold.md)

